

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext

object WordCount{

    def main(args:Array[String]):Unit={
        val conf=new SparkConf()
                .setAppName("WordCount")
                .setMaster("local[*]")
        val sc=new SparkContext(conf)
        val textFile=sc.textFile(args(0))

        val counts=textFile
                    .flatMap(line=>line.split("\\s+"))
                    .map(word=>(word.toLowerCase,1))
                    .reduceByKey(_+_)
        
        
        counts.saveAsTextFile(args(1))

        sc.stop()
    }

}








find /usr -name "hadoop*sources*.jar"
find ~ -name "hadoop*sources*.jar"

////////////Copy path

start-dfs.sh
start-yarn.sh
jps

unzip path(of jar) OR jar xf path
ls  //check org
cd /org/apache/hadoop/...


cp (path of wordcount.java) Mock(path)
cd Mock
nano WordCount.java
// copy paste remove license and packages


javac -cp $(hadoop classpath) WordCount.java
jar cf WordCount.jar WordCount*.class
hdfs dfs -rm -r /input /output
hdfs dfs -mkdir /input
hdfs dfs -put ./input.txt /input
hadoop jar WordCount.jar WordCount /input/input.txt /output
hdfs dfs -cat /output/part-r-00000










code


spark-shell -i WordCount.scala(path) 



echo $SPARK_HOME                /// ~/ .bashrc
scalac -cp 'path/jars/*' WordCount.scala
jar cf WordCount.jar WordCount*.class
spark-submit --class WordCount WordCount.jar file://iput(path) file://output(path)





Sure! Let‚Äôs break it down clearly and systematically:

---

# üìö What is Hadoop?

**Hadoop** is an **open-source framework** designed to store and process **large volumes of data** (big data) across many computers in a **distributed** and **fault-tolerant** manner.

‚úÖ It handles structured, semi-structured, and unstructured data.

‚úÖ It is scalable (can add more computers easily).

‚úÖ It is cost-effective (runs on commodity hardware).

---

# üèõÔ∏è Hadoop Architecture Overview

Hadoop mainly consists of two core components:

1. **HDFS (Hadoop Distributed File System)** ‚Üí for **storage**.
2. **MapReduce** ‚Üí for **processing**.

Besides these, it also has **YARN (Yet Another Resource Negotiator)** to manage cluster resources.

The architecture has mainly **two types of nodes**:

| Node Type | Function |
|:----------|:---------|
| **Master Node** | Controls and manages the system. |
| **Slave Node** | Stores actual data and performs computations. |

---

# üñ•Ô∏è Components and Their Working

## 1. **HDFS (Storage System)**

- **Master Node ‚Üí NameNode**
  - Manages the **filesystem namespace**.
  - Keeps **metadata** (file names, locations of blocks, permissions).
  - Does **not store the actual data** ‚Äî only information **about** data.

- **Slave Nodes ‚Üí DataNodes**
  - Actually **store the data** (block files).
  - Send periodic heartbeats to NameNode to tell they're alive.
  - Handle requests like **read**, **write**, **replication**.

- **Secondary NameNode**
  - It is **not** a backup NameNode.
  - It **periodically merges** the NameNode‚Äôs metadata (edit logs + fsimage) to prevent memory overflow.
  - Assists in failure recovery **but can't** fully replace NameNode immediately.

---

## 2. **YARN (Resource Management System)**

- **ResourceManager (Master)**
  - Manages **resources** across all nodes.
  - Handles **job scheduling**.
  
- **NodeManager (Slave)**
  - Runs on each machine.
  - Manages **containers** (execution environments).
  - Reports node health and resource usage to ResourceManager.

---

## 3. **MapReduce (Processing Framework)**

- Divides jobs into **Map tasks** and **Reduce tasks**.
- **Map** Phase:
  - Input data is split and processed into (key, value) pairs.
- **Shuffle and Sort** Phase:
  - Intermediate data is transferred and sorted between Map and Reduce.
- **Reduce** Phase:
  - Aggregates results from Map phase.

> Example: Counting the number of occurrences of words in a file.

---

# üîµ How the Nodes Work Together (Simplified Example):

1. **Client** submits a file.
2. **NameNode** splits the file into **blocks** (default 128 MB) and decides which **DataNodes** to store these blocks.
3. Blocks are stored **with replication** (usually 3 copies) on different **DataNodes**.
4. **ResourceManager** accepts the job request and assigns work to **NodeManagers**.
5. **NodeManagers** launch **Map tasks** and **Reduce tasks** in containers.
6. After processing, results are sent back to the **client**.

---

# üéØ Why is Hadoop Used? (Importance)

| Reason | Explanation |
|:-------|:------------|
| **Handles Big Data** | Can process petabytes (even exabytes) of data. |
| **Fault Tolerant** | If one node fails, Hadoop retrieves data from other replicated copies. |
| **Scalable** | Easily add more machines to the cluster. |
| **Cost-Effective** | Runs on normal, cheap hardware (no need for supercomputers). |
| **Flexible** | Can store any type of data (text, images, videos, logs, etc.). |
| **Open-source** | Free to use and backed by a strong community. |

---

# üî• Diagram to Visualize Hadoop Architecture
```
+---------------------------+
|         Client            |
+---------------------------+
           |
        Submit Job
           ‚Üì
+---------------------------+
|         NameNode          | ‚Üê (HDFS - Master)
+---------------------------+
        /        \
+------------+  +------------+
| DataNode 1 |  | DataNode 2 |  ... (HDFS - Slaves)
+------------+  +------------+

+---------------------------+
|      ResourceManager      | ‚Üê (YARN - Master)
+---------------------------+
        /        \
+------------+  +------------+
| NodeManager|  | NodeManager|  ... (YARN - Slaves)
+------------+  +------------+
```

---

# üìù Quick Summary

| Component | Type | Responsibility |
|:---------|:-----|:----------------|
| NameNode | Master | Manages metadata (HDFS) |
| DataNode | Slave | Stores actual data blocks |
| ResourceManager | Master | Manages resources and job scheduling |
| NodeManager | Slave | Manages job execution on a single node |
| Secondary NameNode | Helper | Helps NameNode in checkpointing |

---

Would you also like me to give you a **real-world example** (like how Facebook or Amazon uses Hadoop)? üöÄ It helps in remembering it better! üéØ


















Good question! Let's dive into **how Hadoop manages replication** of data inside **HDFS (Hadoop Distributed File System)**:

---

# üîµ How Hadoop Manages Replication

When a file is stored in HDFS, it is divided into **blocks** (typically **128 MB** or **256 MB** per block).  
Each block is **replicated** (by default **3 copies**) across different **DataNodes**.

This ensures **fault tolerance** ‚Äî if one node goes down, the data is **still available** from another copy.

---

# ‚öôÔ∏è Detailed Working of Replication

### 1. **During File Write (Initial Replication)**

- The client contacts the **NameNode** to write a file.
- The **NameNode**:
  - Splits the file into blocks.
  - Decides **which DataNodes** will store each block **and its replicas**.
- Data is written like a **pipeline**:
  - The client writes the first replica to **DataNode A**.
  - **DataNode A** then forwards the block to **DataNode B**.
  - **DataNode B** forwards to **DataNode C**.
- So the **client only connects to the first DataNode**, and the rest happens internally.

This is called **pipelined replication**. üö∞

---

### 2. **Choosing DataNodes for Replicas (Rack Awareness)**

Hadoop tries to place replicas smartly across the cluster:

| Replica No. | Placement |
|:------------|:----------|
| 1st Replica | On a node in the local rack (where the client is writing from) |
| 2nd Replica | On a node in a different rack |
| 3rd Replica | On a different node in the same remote rack |

‚úÖ This design makes sure that **even if a full rack fails**, data is not lost.

---
  
### 3. **Replication Factor**

- **Default replication factor**: **3** (can be configured).
- You can set different replication factors **per file** or **per directory**.

Example command to set replication:
```bash
hdfs dfs -setrep -w 2 /path/to/file
```
This sets replication **to 2** for that file.

---

### 4. **Replication Monitoring and Maintenance**

- **DataNodes** send regular **heartbeat signals** to the **NameNode**.
- If a **DataNode fails**:
  - NameNode notices missing replicas.
  - It chooses **other healthy DataNodes**.
  - It **automatically replicates** missing blocks to maintain the desired replication factor.

‚úÖ **Self-healing mechanism**.

---

# üõ†Ô∏è Example

Suppose you have a 400 MB file, block size is 128 MB, replication factor is 3:

| Block | Size | Replicas |
|:------|:-----|:---------|
| Block 1 | 128 MB | 3 replicas |
| Block 2 | 128 MB | 3 replicas |
| Block 3 | 128 MB | 3 replicas |
| Block 4 | 16 MB  | 3 replicas |

Total **number of block copies** stored = **(4 blocks √ó 3 replicas) = 12 block copies**.

So the actual storage consumed = much more than just 400 MB ‚Äî it‚Äôs **400 MB √ó 3** approximately.

---

# üß† Important Properties

| Feature | Detail |
|:--------|:-------|
| **High availability** | Because of multiple replicas |
| **Rack awareness** | Spread replicas across racks |
| **Automatic replication** | If node fails, new replicas are created |
| **Configurable replication** | Can be tuned as needed |

---

# ‚ú® Quick Diagram

```
File: "data.txt" ‚Üí split into 2 blocks (Block A and Block B)

+---------------------------+
|        NameNode           |
|  - Tracks where blocks are|
|  - Handles replication    |
+---------------------------+
         /        \
        ‚Üì          ‚Üì
+----------+   +----------+
| DataNode1|   | DataNode2|   (Block A copy)
+----------+   +----------+
        ‚Üì           ‚Üì
+----------+   +----------+
| DataNode3|   | DataNode4|   (Block B copy)
+----------+   +----------+
```

If **DataNode2** fails, NameNode will **re-replicate** Block A to another healthy DataNode.

---

# üöÄ Quick Summary
- Hadoop keeps **multiple copies** of each data block.
- Replication ensures **fault tolerance** and **availability**.
- Replicas are **strategically placed** across racks (Rack Awareness).
- Replication is **automatically monitored and repaired** by the **NameNode**.

---

Would you like me also to explain **what happens during a "block corruption" case** and **how Hadoop handles it**? üöÄ (It's a cool internal working!)




















Of course! Let's explain **Apache Spark architecture** just like we did for Hadoop ‚Äî clearly and step-by-step:

---

# üìö What is Apache Spark?

**Spark** is a **fast**, **open-source**, **distributed computing** system used for **big data processing**.

‚úÖ It processes data **in-memory** (in RAM) ‚Äî much faster than Hadoop's disk-based MapReduce.

‚úÖ It supports **batch processing**, **stream processing**, **machine learning**, **SQL queries**, and even **graph processing**.

‚úÖ It can run **on top of Hadoop**, standalone, or even on cloud clusters.

---

# üèõÔ∏è Spark Architecture Overview

Spark architecture mainly has **two types of nodes**:

| Node Type | Role |
|:----------|:-----|
| **Driver** | Master node controlling the execution |
| **Worker** | Slave nodes that perform tasks |

Internally, it also uses:

- **Cluster Manager** ‚Üí Manages resources across machines.
- **Executors** ‚Üí Processes launched on Workers.
- **Tasks** ‚Üí Actual units of work.

---

# üñ•Ô∏è Components and Their Working

## 1. **Driver Program (Master)**

- Runs the **main()** function of the Spark application.
- Creates a **SparkContext** (the entry point of Spark).
- **Plans** jobs into **tasks** and **schedules** them.
- Coordinates between all the **executors**.
- Maintains information about the **RDDs (Resilient Distributed Datasets)**, transformations, and actions.

‚úÖ Think of it as the "brain" of your Spark job.

---

## 2. **Cluster Manager**

- Manages the cluster resources.
- Spark can work with different cluster managers:
  - **Standalone** (built-in Spark manager)
  - **Apache YARN** (same as Hadoop's resource manager)
  - **Apache Mesos**
  - **Kubernetes**

‚úÖ It tells Spark where it can launch Executors.

---

## 3. **Worker Nodes**

- These are the **machines** where the real computation happens.
- Each Worker node runs:
  - One or more **Executors**.

---

## 4. **Executors**

- Executors **run on Worker nodes**.
- They are **responsible for**:
  - **Executing tasks** assigned by the Driver.
  - **Storing data** (in-memory or disk) for **caching** (important for speeding up iterative algorithms like ML).
- Each Spark application has its own set of Executors.

‚úÖ If an Executor dies, Spark can relaunch it (depending on settings).

---

## 5. **Tasks**

- A **task** is the **smallest unit of work** in Spark.
- Each job is **split into multiple tasks** based on data partitions.
- Executors run the tasks.

---

# üîµ How the Nodes Work Together (Simplified Example):

1. The user submits a Spark application (say, a Python or Scala program).
2. The **Driver** creates a **SparkContext** and requests resources from the **Cluster Manager**.
3. The **Cluster Manager** allocates **Workers** to run **Executors**.
4. The Driver **divides a job into multiple tasks**.
5. These **tasks are sent to Executors**.
6. **Executors** perform the computation and send the results back to the **Driver**.

---

# ‚ú® Quick Diagram

```
+------------------+
|   Driver Program  |
| (SparkContext)    |
+------------------+
         |
         ‚Üì
+--------------------------+
|   Cluster Manager        |
| (Standalone, YARN, etc.) |
+--------------------------+
         |
         ‚Üì
+--------------+      +--------------+
| Worker Node 1|      | Worker Node 2 |
| + Executor   |      | + Executor    |
+--------------+      +--------------+
         ‚Üì                  ‚Üì
    Runs Tasks          Runs Tasks
```

---

# ‚ö° Key Concept: RDD (Resilient Distributed Dataset)

- Fundamental data structure in Spark.
- **Immutable** distributed collection of objects.
- RDDs are split into **partitions** and processed **in parallel**.

‚úÖ Fault-tolerant ‚Äî if a node fails, RDD can be recomputed using **lineage information**.

---

# üéØ Why is Spark Used? (Importance)

| Reason | Explanation |
|:-------|:------------|
| **In-Memory Computation** | Data stored in RAM ‚Üí faster than Hadoop MapReduce (which reads/writes disk). |
| **Fault Tolerant** | RDDs remember how to recreate data if a node fails. |
| **Versatile** | Supports SQL, Streaming, Machine Learning (MLlib), Graph processing (GraphX). |
| **Compatible** | Can run on Hadoop (YARN), Kubernetes, Standalone. |
| **Easy to Use** | Supports Java, Scala, Python, R APIs. |

---

# üß† Example Flow (WordCount)

Suppose you want to count the number of times each word appears in a file:

1. **Driver** reads input file ‚Üí creates RDD.
2. RDD is split into partitions.
3. Each **Executor** counts word frequencies for its partition (Map Phase).
4. Results are combined (Reduce Phase).
5. Final count is collected back to the **Driver**.

‚úÖ All major computation happens in Executors.

---

# üõ†Ô∏è Quick Comparison: Hadoop vs Spark

| Feature | Hadoop MapReduce | Spark |
|:--------|:-----------------|:------|
| **Speed** | Slow (disk-based) | Fast (in-memory) |
| **Processing** | Batch only | Batch + Streaming |
| **Ease of use** | More complex | Simpler APIs |
| **Fault Tolerance** | Replication-based | Lineage-based |
| **Best for** | Massive archival jobs | Real-time and iterative jobs |

---

# üöÄ Quick Summary

| Component | Type | Responsibility |
|:---------|:-----|:----------------|
| Driver | Master | Controls job flow and task scheduling |
| Cluster Manager | Master | Allocates resources |
| Worker | Slave | Hosts executors |
| Executor | Worker process | Runs tasks and stores data |
| Task | Work unit | Smallest execution unit |

---

Would you also like me to quickly explain **how Spark handles failures** (e.g., if an Executor crashes)? It‚Äôs quite interesting how **RDD lineage** helps here! üöÄ Let me know!



















